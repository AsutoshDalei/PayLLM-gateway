{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c915c8b-8e32-4870-bdaf-aa6118a70f96",
   "metadata": {},
   "source": [
    "# Testing out Local LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d25a7e3-d464-477f-9c07-417f6fd62be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a12c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96ebef53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are PayLLM, a conversational payment assistant. NEVER call tools until you have collected all required information:  You should never use external knowledge, assumptions or information beyond what is explicitly shared or recieved. Follow this structured flow and do NOT call tools unless all required information is available: 1. Greet the user if they greet you. 2. Ask for the user their state and the service they want to pay the bill for. 3. Get the list of service providers using fetch_service_provider tool. 4. Ask for the service provider. 5. Ask for the bill number. 6. Confirm fetching the bill. 7. Display the bill amount. 8. Ask for payment confirmation. 9. Confirm payment. Maintain the flow based on previous responses.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = (\"You are PayLLM, a conversational payment assistant. NEVER call tools until you have collected all required information:\\n\\n\"\n",
    "\"You should never use external knowledge, assumptions or information beyond what is explicitly shared or recieved.\\n\"\n",
    "\"Follow this structured flow and do NOT call tools unless all required information is available:\\n\"\n",
    "\"1. Greet the user if they greet you.\\n\"\n",
    "\"2. Ask for the user their state and the service they want to pay the bill for.\\n\"\n",
    "\"3. Get the list of service providers using fetch_service_provider tool.\\n\"\n",
    "\"4. Ask for the service provider.\\n\"\n",
    "\"5. Ask for the bill number.\\n\"\n",
    "\"6. Confirm fetching the bill.\\n\"\n",
    "\"7. Display the bill amount.\\n\"\n",
    "\"8. Ask for payment confirmation.\\n\"\n",
    "\"9. Confirm payment.\\n\"\n",
    "\"Maintain the flow based on previous responses.\")\n",
    "\n",
    "' '.join(tt.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "844092bb-1bd2-4037-baaf-5ed9f413838a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "# llm = ChatOllama(model=\"llama3.2:1b\", temperature=0)\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d955cf4-be35-4075-b37d-3ea3c2772731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"To proceed with paying your bill, I need to know a few details first.\\n\\nCan you please tell me the number of the bill you'd like to pay?\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-02-12T22:14:36.447587Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1133021959, 'load_duration': 29848625, 'prompt_eval_count': 127, 'prompt_eval_duration': 201000000, 'eval_count': 33, 'eval_duration': 900000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-d4d26844-08a5-4aad-9a64-013bf559dd9c-0', usage_metadata={'input_tokens': 127, 'output_tokens': 33, 'total_tokens': 160})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialSystemMessage = '''You are an excellent virtual assistant to help with payment of bills.\n",
    "You should follow the following steps strictly to pay the bills:\n",
    "1. Ask the user the bill number\n",
    "2. Ask the user if you should fetch the bill details.\n",
    "3. Inform the user the bill details once fetched.\n",
    "4. Ask the user if you should pay the bill.\n",
    "5. Is the user agrees, pay the bill.\n",
    "\n",
    "You should never user external knowledge, assumptions or information beyond what is explicitly shared or recieved.\n",
    "'''\n",
    "\n",
    "\n",
    "messages = [\n",
    "    (\"system\",initialSystemMessage),\n",
    "    (\"human\", \"Pay my bill\")\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ce8425-ee02-4c78-afb8-e0a206f795fe",
   "metadata": {},
   "source": [
    "## Testing Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae52d71-5e10-4665-9499-9f2f21833d05",
   "metadata": {},
   "source": [
    "### Calculator Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1556dfef-a5f2-4ef0-afde-693a75ff0184",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add (+) two numbers\"\"\"\n",
    "    return a+b\n",
    "    \n",
    "@tool\n",
    "def sub(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract (-) two numbers\"\"\"\n",
    "    return a-b\n",
    "    \n",
    "@tool\n",
    "def mul(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply (*, x) two numbers\"\"\"\n",
    "    return a*b\n",
    "    \n",
    "@tool\n",
    "def div(a: int, b: int) -> int:\n",
    "    \"\"\"Divide (/) two numbers\"\"\"\n",
    "    return a/b\n",
    "\n",
    "@tool\n",
    "def fetchUserDets(name: str) -> str:\n",
    "    \"\"\"Function to fetch user details. Input is name of the user. Output relevant details.\"\"\"\n",
    "    # hmap = \n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "tools = [mul, div, add, sub]\n",
    "toolsMap = {'add':add, \"sub\":sub, \"mul\":mul, \"div\":div}\n",
    "\n",
    "llmTools = llm.bind_tools(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0cdbb0-94b7-4241-a71f-996319510ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c77b6c9a-6435-468e-b793-1e7b0f703e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-02-24T23:26:50.365703Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1046341750, 'load_duration': 33897542, 'prompt_eval_count': 347, 'prompt_eval_duration': 215000000, 'eval_count': 28, 'eval_duration': 795000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-5029179c-cd05-42d2-842b-2a7f364e646f-0', tool_calls=[{'name': 'add', 'args': {'a': '3 * 12', 'b': '8 * 213'}, 'id': '2d90d4f5-9bda-497f-b61b-4514d504997c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 347, 'output_tokens': 28, 'total_tokens': 375})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Add 3 and 4?\"\n",
    "query = \"What is 3 multiplied 12? Also, what is 11 + 49?\"\n",
    "\n",
    "# llmTools.invoke(query).tool_calls\n",
    "\n",
    "messages = [\n",
    "    (\"system\",\"You are a helpful assistant. be kind\"),\n",
    "    (\"human\", \"Tell me the answer to 3 * 12+8 * 213\")\n",
    "]\n",
    "ai_msg = llmTools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b2d74fa-2cd2-480f-8b64-107c5b25dcd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'a': '3 * 12', 'b': '8 * 213'},\n",
       "  'id': '2d90d4f5-9bda-497f-b61b-4514d504997c',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75446aba-e14a-4498-88fe-100b5ed65215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('system', 'You are a helpful assistant. be kind'),\n",
       " ('human', 'Tell me the answer to 3 * 12+8 * 213'),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-02-24T23:26:50.365703Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1046341750, 'load_duration': 33897542, 'prompt_eval_count': 347, 'prompt_eval_duration': 215000000, 'eval_count': 28, 'eval_duration': 795000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-5029179c-cd05-42d2-842b-2a7f364e646f-0', tool_calls=[{'name': 'add', 'args': {'a': '3 * 12', 'b': '8 * 213'}, 'id': '2d90d4f5-9bda-497f-b61b-4514d504997c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 347, 'output_tokens': 28, 'total_tokens': 375})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0e11b63-9d16-4ad8-9c9c-17f4e1893d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"placeholder\", \"{msgs}\") # <-- This is the changed part\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0933bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='helli hela!', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.invoke({\"msgs\": [HumanMessage(content=\"helli hela!\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17aa6318-8cc8-4256-9683-81acf6dc2b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg = llmTools.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5513aaf5-cfbf-4ee0-b14a-a9d21318949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer to 3 * 12 is 36.\n",
      "\n",
      "The answer to 11 - 49 is -38.\n"
     ]
    }
   ],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc85ddc1-4f89-4a8d-b8d4-a35f39677769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The answer to 3 * 12 is 36.\\n\\nThe answer to 11 - 49 is -38.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-02-24T23:24:26.259054Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1108464084, 'load_duration': 31862125, 'prompt_eval_count': 142, 'prompt_eval_duration': 388000000, 'eval_count': 25, 'eval_duration': 685000000, 'message': Message(role='assistant', content='The answer to 3 * 12 is 36.\\n\\nThe answer to 11 - 49 is -38.', images=None, tool_calls=None)}, id='run-a1d082b4-c1cd-4821-b174-4d7676facfed-0', usage_metadata={'input_tokens': 142, 'output_tokens': 25, 'total_tokens': 167})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afd6eab1-dcee-4fbf-996f-79c503343156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer to 3 * 12 is 36.\n",
      "\n",
      "The answer to 11 - 49 is -38.\n"
     ]
    }
   ],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802134be-f20a-4a53-96e7-9799f1b4e651",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "647913ff-0048-4abe-a09c-62b4324f980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "import traceback\n",
    "\n",
    "# Initialize the LLaMA 3.2 model\n",
    "model = ChatOllama(model=\"llama3.2:latest\", temperature=0)\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c690731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = '''Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}'''\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b479d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24821276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5aa9717b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are PayLLM, a conversational payment assistant. Follow this structured flow:\n",
      "1. Greet the user if they greet you.\n",
      "2. Ask for the user's state.\n",
      "3. Ask for the service provider.\n",
      "4. Ask for the bill number.\n",
      "5. Confirm fetching the bill.\n",
      "6. Display the bill amount.\n",
      "7. Ask for payment confirmation.\n",
      "8. Confirm payment.\n",
      "Maintain the flow based on previous responses.\n"
     ]
    }
   ],
   "source": [
    "print('''You are PayLLM, a conversational payment assistant. Follow this structured flow:\n",
    "1. Greet the user if they greet you.\n",
    "2. Ask for the user's state.\n",
    "3. Ask for the service provider.\n",
    "4. Ask for the bill number.\n",
    "5. Confirm fetching the bill.\n",
    "6. Display the bill amount.\n",
    "7. Ask for payment confirmation.\n",
    "8. Confirm payment.\n",
    "Maintain the flow based on previous responses.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88c80ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are PayLLM, a conversational payment assistant. NEVER call tools until you have collected all required information:\n",
      "You should never use external knowledge, assumptions or information beyond what is explicitly shared or recieved.\n",
      "Follow this strict sequence and do NOT proceed to the next step unless all information from the previous step is available:\n",
      "1. Greet the user if they greet you.\n",
      "2. Ask for the user their state and the service they want to pay the bill for.\n",
      "3. Get the list of service providers using fetch_service_provider tool.\n",
      "4. Ask for the service provider.\n",
      "5. Ask for the bill number.\n",
      "6. Confirm fetching the bill.\n",
      "7. Display the bill amount.\n",
      "8. Ask for payment confirmation.\n",
      "9. Confirm payment.\n",
      "Maintain the flow based on previous responses.\n"
     ]
    }
   ],
   "source": [
    "print(\"You are PayLLM, a conversational payment assistant. NEVER call tools until you have collected all required information:\\n\"\n",
    "               \"You should never use external knowledge, assumptions or information beyond what is explicitly shared or recieved.\\n\"\n",
    "               \"Follow this strict sequence and do NOT proceed to the next step unless all information from the previous step is available:\\n\"\n",
    "               \"1. Greet the user if they greet you.\\n\"\n",
    "               \"2. Ask for the user their state and the service they want to pay the bill for.\\n\"\n",
    "               \"3. Get the list of service providers using fetch_service_provider tool.\\n\"\n",
    "               \"4. Ask for the service provider.\\n\"\n",
    "               \"5. Ask for the bill number.\\n\"\n",
    "               \"6. Confirm fetching the bill.\\n\"\n",
    "               \"7. Display the bill amount.\\n\"\n",
    "               \"8. Ask for payment confirmation.\\n\"\n",
    "               \"9. Confirm payment.\\n\"\n",
    "               \"Maintain the flow based on previous responses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071464f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
